{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: black;\"><center>Diplomado de Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: purple;\"><center>Detector de Objetos</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: black;\">Presentado por:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: purple;\">Andrés Felipe Nieto Grandas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: purple;\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p>En este cuaderno me propongo a ilustrar el proceso de preparacion de datos, modelamiento y entrenamiento de una maquina capáz Detectar todo tipo de objetos.</p>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GInxd6Quo1H"
   },
   "source": [
    "### <span style=\"color:purple\">Importamos las librerias necesarias</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2593,
     "status": "ok",
     "timestamp": 1622441506096,
     "user": {
      "displayName": "Andres Felipe Nieto Grandas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVwnHrOcAcuO7hAAvGfu388UdN50UtNnedLL27=s64",
      "userId": "12110662847858295180"
     },
     "user_tz": 300
    },
    "id": "PRMlfKuKupbk",
    "outputId": "e3e122fd-d225-4247-8438-9f5b8038c05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSWJzLd3ug3c"
   },
   "source": [
    "### <span style=\"color:purple\">Hiperparametros del modelo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRNOVx2Mu3DO"
   },
   "source": [
    " \n",
    "\n",
    "\n",
    "#### <span style=\"color:black\">**_MODEL_SIZE** se refiere al tamaño de la entrada del modelo, casi todas las capas convolucionales en Yolo tienen batch normalization despues de ella. Esto ayuda a el modelo a entrenar de manera mas rapida y redice la varianza entre las unidades (y la varianza todal tambien). Batch normalization se define de la siguiente forma. **_BATCH_NORM_EPSILON** hace referencia a epsilon en la formula, donde como **_BATCH_NORM_DECAY** hace referencia al momentum.</span>\n",
    "\n",
    "\n",
    "#### <span style=\"color:black\">**Leaky ReLU** es una ligera modificacion de la función de activacion **RELU**. La idea detras de **Leaky ReLU** es prevenir lo que se conoce como \"neurona moribunda\" cuando una gran cantidad de activaciones se convierten en 0. **_LEAKY_RELU** hace referencia a alpha.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGdg16Q1uZsh"
   },
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "            (30, 61), (62, 45), (59, 119),\n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1622441507170,
     "user": {
      "displayName": "Andres Felipe Nieto Grandas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVwnHrOcAcuO7hAAvGfu388UdN50UtNnedLL27=s64",
      "userId": "12110662847858295180"
     },
     "user_tz": 300
    },
    "id": "dD0JY5yrBUBh",
    "outputId": "034d7cda-fc8b-426f-a550-91a38529bc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "ruta = 'gdrive/My Drive/Colab Notebooks/Reto 4/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF7XNWbEu2TQ"
   },
   "source": [
    "#### <span style=\"color:black\">**Batch norm** y **fixed padding**, Es útil definir la función batch_norm ya que el modelo usa **Batch norm** con parámetros compartidos en gran medida. Además, al igual que ResNet, Yolo usa convolución con relleno fijo, lo que significa que el relleno se define solo por el tamaño del kernel.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC6cGsrduyYP"
   },
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "    \"\"\"Usa batch normalization utilizando un set estandar de parametros.\"\"\"\n",
    "    return tf.layers.batch_normalization(\n",
    "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
    "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
    "        scale=True, training=training)\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \"\"\"implementación ResNet de fixed padding.\n",
    "\n",
    "    Args:\n",
    "        inputs: Tensor input to be padded.\n",
    "        kernel_size: The kernel to be used in the conv2d or max_pool2d.\n",
    "        data_format: The input format.\n",
    "    Returns:\n",
    "        A tensor with the same format as the input.\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                        [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end], [0, 0]])\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "    \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
    "        use_bias=False, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_V9CgAEHwQU"
   },
   "source": [
    "## <span style=\"color:purple\"> Extracción de características: Darknet-53</span>\n",
    "#### <span style=\"color:black\">Para la extracción de características, Yolo utiliza la red neuronal Darknet-53 previamente entrenada en ImageNet. Al igual que ResNet, Darknet-53 tiene conexiones de acceso directo (residuales), que ayudan a que la información de capas anteriores fluya más. Omitimos las últimas 3 capas (Avgpool, Connected y Softmax) ya que solo necesitamos las características.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1vk1hUnyC2R"
   },
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format,\n",
    "                             strides=1):\n",
    "    \"\"\"Creates a residual block for Darknet.\"\"\"\n",
    "    shortcut = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs += shortcut\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def darknet53(inputs, training, data_format):\n",
    "    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
    "                                      data_format=data_format)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(2):\n",
    "        inputs = darknet53_residual_block(inputs, filters=64,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=128,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    route1 = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    route2 = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    return route1, route2, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8rb9WazIGQl"
   },
   "source": [
    "### <span style=\"color:purple\">Capas Convolucionales</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLDRufuwycZu"
   },
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    route = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    return route, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg_TYjqRIciE"
   },
   "source": [
    "## <span style=\"color:purple\">Capas de detección</span>\n",
    "#### <span style=\"color:black\">Yolo tiene 3 capas de detección, que detectan en 3 escalas diferentes utilizando los respectivos anclajes. Para cada celda en el mapa de características, la capa de detección predice valores de n_anclajes * (5 + n_clases) usando convolución 1x1. Para cada escala tenemos n_anclajes = 3. 5 + n_clases significa que respectivamente para cada uno de los 3 anclajes vamos a predecir 4 coordenadas de la caja, su puntuación de confianza (la probabilidad de contener un objeto) y las probabilidades de clase.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAtKi9DNyfG3"
   },
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    \"\"\"Creates Yolo final detection layer.\n",
    "\n",
    "    Detects boxes with respect to anchors.\n",
    "\n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of labels.\n",
    "        anchors: A list of anchor sizes.\n",
    "        img_size: The input size of the model.\n",
    "        data_format: The input format.\n",
    "\n",
    "    Returns:\n",
    "        Tensor output.\n",
    "    \"\"\"\n",
    "    n_anchors = len(anchors)\n",
    "\n",
    "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
    "                              kernel_size=1, strides=1, use_bias=True,\n",
    "                              data_format=data_format)\n",
    "\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
    "                                 5 + n_classes])\n",
    "\n",
    "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "\n",
    "    box_centers, box_shapes, confidence, classes = \\\n",
    "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
    "\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x, y)\n",
    "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "\n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "\n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "\n",
    "    inputs = tf.concat([box_centers, box_shapes,\n",
    "                        confidence, classes], axis=-1)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATLTAwTlIzap"
   },
   "source": [
    "## <span style=\"color:purple\">Capa de muestra superior</span>\n",
    "#### <span style=\"color:black\">Para concatenar con salidas de acceso directo de Darknet-53 antes de aplicar la detección en una escala diferente, vamos a muestrear el mapa de características utilizando la interpolación del vecino más cercano.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWGvWJYPys35"
   },
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "    \"\"\"Upsamples to `out_shape` using nearest neighbor interpolation.\"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeEgbjAsI-J3"
   },
   "source": [
    "## <span style=\"color:purple\">Supresión Non-max</span>\n",
    "#### <span style=\"color:black\">El modelo producirá muchas cajas, por lo que necesitamos una forma de descartar las cajas con puntuaciones de confianza bajas. Además, para evitar tener varias casillas para un objeto, descartaremos las casillas con una superposición alta y utilizaremos la supresión no máxima para cada clase.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJE-q9_Syvc8"
   },
   "outputs": [],
   "source": [
    "def build_boxes(inputs):\n",
    "    \"\"\"Computes top left and bottom right points of the boxes.\"\"\"\n",
    "    center_x, center_y, width, height, confidence, classes = \\\n",
    "        tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)\n",
    "\n",
    "    top_left_x = center_x - width / 2\n",
    "    top_left_y = center_y - height / 2\n",
    "    bottom_right_x = center_x + width / 2\n",
    "    bottom_right_y = center_y + height / 2\n",
    "\n",
    "    boxes = tf.concat([top_left_x, top_left_y,\n",
    "                       bottom_right_x, bottom_right_y,\n",
    "                       confidence, classes], axis=-1)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold,\n",
    "                        confidence_threshold):\n",
    "    \"\"\"Performs non-max suppression separately for each class.\n",
    "\n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of classes.\n",
    "        max_output_size: Max number of boxes to be selected for each class.\n",
    "        iou_threshold: Threshold for the IOU.\n",
    "        confidence_threshold: Threshold for the confidence score.\n",
    "    Returns:\n",
    "        A list containing class-to-boxes dictionaries\n",
    "            for each sample in the batch.\n",
    "    \"\"\"\n",
    "    batch = tf.unstack(inputs)\n",
    "    boxes_dicts = []\n",
    "    for boxes in batch:\n",
    "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
    "        classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
    "        classes = tf.expand_dims(tf.to_float(classes), axis=-1)\n",
    "        boxes = tf.concat([boxes[:, :5], classes], axis=-1)\n",
    "\n",
    "        boxes_dict = dict()\n",
    "        for cls in range(n_classes):\n",
    "            mask = tf.equal(boxes[:, 5], cls)\n",
    "            mask_shape = mask.get_shape()\n",
    "            if mask_shape.ndims != 0:\n",
    "                class_boxes = tf.boolean_mask(boxes, mask)\n",
    "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,\n",
    "                                                              [4, 1, -1],\n",
    "                                                              axis=-1)\n",
    "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
    "                indices = tf.image.non_max_suppression(boxes_coords,\n",
    "                                                       boxes_conf_scores,\n",
    "                                                       max_output_size,\n",
    "                                                       iou_threshold)\n",
    "                class_boxes = tf.gather(class_boxes, indices)\n",
    "                boxes_dict[cls] = class_boxes[:, :5]\n",
    "\n",
    "        boxes_dicts.append(boxes_dict)\n",
    "\n",
    "    return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdB4XajsJQpx"
   },
   "source": [
    "## <span style=\"color:purple\">Clase final del modelo</span>\n",
    "#### <span style=\"color:black\">Finalmente, definamos la clase de modelo usando todas las capas descritas anteriormente.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1p3Q3RlyzF9"
   },
   "outputs": [],
   "source": [
    "class Yolo_v3:\n",
    "    \"\"\"Yolo v3 model class.\"\"\"\n",
    "\n",
    "    def __init__(self, n_classes, model_size, max_output_size, iou_threshold,\n",
    "                 confidence_threshold, data_format=None):\n",
    "        \"\"\"Creates the model.\n",
    "\n",
    "        Args:\n",
    "            n_classes: Number of class labels.\n",
    "            model_size: The input size of the model.\n",
    "            max_output_size: Max number of boxes to be selected for each class.\n",
    "            iou_threshold: Threshold for the IOU.\n",
    "            confidence_threshold: Threshold for the confidence score.\n",
    "            data_format: The input format.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        if not data_format:\n",
    "            if tf.test.is_built_with_cuda():\n",
    "                data_format = 'channels_first'\n",
    "            else:\n",
    "                data_format = 'channels_last'\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.model_size = model_size\n",
    "        self.max_output_size = max_output_size\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.data_format = data_format\n",
    "\n",
    "    def __call__(self, inputs, training):\n",
    "        \"\"\"Add operations to detect boxes for a batch of input images.\n",
    "\n",
    "        Args:\n",
    "            inputs: A Tensor representing a batch of input images.\n",
    "            training: A boolean, whether to use in training or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            A list containing class-to-boxes dictionaries\n",
    "                for each sample in the batch.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('yolo_v3_model'):\n",
    "            if self.data_format == 'channels_first':\n",
    "                inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "            inputs = inputs / 255\n",
    "\n",
    "            route1, route2, inputs = darknet53(inputs, training=training,\n",
    "                                               data_format=self.data_format)\n",
    "\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=512, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect1 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[6:9],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
    "                                          data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training,\n",
    "                                data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route2.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                              data_format=self.data_format)\n",
    "            axis = 1 if self.data_format == 'channels_first' else 3\n",
    "            inputs = tf.concat([inputs, route2], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=256, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect2 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[3:6],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1,\n",
    "                                          data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training,\n",
    "                                data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route1.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                              data_format=self.data_format)\n",
    "            inputs = tf.concat([inputs, route1], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=128, training=training,\n",
    "                data_format=self.data_format)\n",
    "            detect3 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                                 anchors=_ANCHORS[0:3],\n",
    "                                 img_size=self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "\n",
    "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
    "\n",
    "            inputs = build_boxes(inputs)\n",
    "\n",
    "            boxes_dicts = non_max_suppression(\n",
    "                inputs, n_classes=self.n_classes,\n",
    "                max_output_size=self.max_output_size,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                confidence_threshold=self.confidence_threshold)\n",
    "\n",
    "            return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVkb3QPFJvWZ"
   },
   "source": [
    "## <span style=\"color:purple\">Funciones de utilidad</span>\n",
    "#### <span style=\"color:black\">Aquí hay algunas funciones de utilidad que nos ayudarán a cargar imágenes como matrices NumPy, cargar nombres de clases desde el archivo oficial y dibujar los cuadros predichos.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOA8PaGSyz09"
   },
   "outputs": [],
   "source": [
    "def load_images(img_names, model_size):\n",
    "    \"\"\"Loads images in a 4D array.\n",
    "\n",
    "    Args:\n",
    "        img_names: A list of images names.\n",
    "        model_size: The input size of the model.\n",
    "        data_format: A format for the array returned\n",
    "            ('channels_first' or 'channels_last').\n",
    "\n",
    "    Returns:\n",
    "        A 4D NumPy array.\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "\n",
    "    for img_name in img_names:\n",
    "        img = Image.open(img_name)\n",
    "        img = img.resize(size=model_size)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_class_names(file_name):\n",
    "    \"\"\"Returns a list of class names read from `file_name`.\"\"\"\n",
    "    with open(file_name, 'r') as f:\n",
    "        class_names = f.read().splitlines()\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
    "    \"\"\"Draws detected boxes.\n",
    "\n",
    "    Args:\n",
    "        img_names: A list of input images names.\n",
    "        boxes_dict: A class-to-boxes dictionary.\n",
    "        class_names: A class names list.\n",
    "        model_size: The input size of the model.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    colors = ((np.array(color_palette(\"hls\", 80)) * 255)).astype(np.uint8)\n",
    "    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names,\n",
    "                                         boxes_dicts):\n",
    "        img = Image.open(img_name)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(font=ruta+'futur.ttf',\n",
    "                                  size=(img.size[0] + img.size[1]) // 100)\n",
    "        resize_factor = \\\n",
    "            (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
    "        for cls in range(len(class_names)):\n",
    "            boxes = boxes_dict[cls]\n",
    "            if np.size(boxes) != 0:\n",
    "                color = colors[cls]\n",
    "                for box in boxes:\n",
    "                    xy, confidence = box[:4], box[4]\n",
    "                    xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
    "                    x0, y0 = xy[0], xy[1]\n",
    "                    thickness = (img.size[0] + img.size[1]) // 200\n",
    "                    for t in np.linspace(0, 1, thickness):\n",
    "                        xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
    "                        xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
    "                        draw.rectangle(xy, outline=tuple(color))\n",
    "                    text = '{} {:.1f}%'.format(class_names[cls],\n",
    "                                               confidence * 100)\n",
    "                    text_size = draw.textsize(text, font=font)\n",
    "                    draw.rectangle(\n",
    "                        [x0, y0 - text_size[1], x0 + text_size[0], y0],\n",
    "                        fill=tuple(color))\n",
    "                    draw.text((x0, y0 - text_size[1]), text, fill='black',\n",
    "                              font=font)\n",
    "\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRXJvt8FJ88I"
   },
   "source": [
    "## <span style=\"color:purple\">Conversión de pesos al formato de Tensorflow</span>\n",
    "#### <span style=\"color:black\">Ahora es el momento de cargar los pesos oficiales. Vamos a iterar a través del archivo y crear gradualmente operaciones tf.assign.</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXwRjD7oy7Ii"
   },
   "outputs": [],
   "source": [
    "def load_weights(variables, file_name):\n",
    "    \"\"\"Reshapes and loads official pretrained Yolo weights.\n",
    "\n",
    "    Args:\n",
    "        variables: A list of tf.Variable to be assigned.\n",
    "        file_name: A name of a file containing weights.\n",
    "\n",
    "    Returns:\n",
    "        A list of assign operations.\n",
    "    \"\"\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        # Skip first 5 values containing irrelevant info\n",
    "        np.fromfile(f, dtype=np.int32, count=5)\n",
    "        weights = np.fromfile(f, dtype=np.float32)\n",
    "\n",
    "        assign_ops = []\n",
    "        ptr = 0\n",
    "\n",
    "        # Load weights for Darknet part.\n",
    "        # Each convolution layer has batch normalization.\n",
    "        for i in range(52):\n",
    "            conv_var = variables[5 * i]\n",
    "            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
    "            batch_norm_vars = [beta, gamma, mean, variance]\n",
    "\n",
    "            for var in batch_norm_vars:\n",
    "                shape = var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(var, var_weights))\n",
    "\n",
    "            shape = conv_var.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "        # Loading weights for Yolo part.\n",
    "        # 7th, 15th and 23rd convolution layer has biases and no batch norm.\n",
    "        ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
    "        unnormalized = [6, 13, 20]\n",
    "        for j in range(3):\n",
    "            for i in ranges[j]:\n",
    "                current = 52 * 5 + 5 * i + j * 2\n",
    "                conv_var = variables[current]\n",
    "                gamma, beta, mean, variance =  \\\n",
    "                    variables[current + 1:current + 5]\n",
    "                batch_norm_vars = [beta, gamma, mean, variance]\n",
    "\n",
    "                for var in batch_norm_vars:\n",
    "                    shape = var.shape.as_list()\n",
    "                    num_params = np.prod(shape)\n",
    "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                    ptr += num_params\n",
    "                    assign_ops.append(tf.assign(var, var_weights))\n",
    "\n",
    "                shape = conv_var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                    (shape[3], shape[2], shape[0], shape[1]))\n",
    "                var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
    "            shape = bias.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(bias, var_weights))\n",
    "\n",
    "            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
    "            shape = conv_var.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "    return assign_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTOdsYC8KPib"
   },
   "source": [
    "## <span style=\"color:purple\">Ejecución del modelo</span>\n",
    "#### <span style=\"color:black\">Ahora podemos ejecutar el modelo usando algunas imágenes de muestra.</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLpwQsZVKkrA"
   },
   "source": [
    "## <span style=\"color:purple\">Imagenes de muestra</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5dfB-92zwn5"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "images = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R7UrC-o2K0R"
   },
   "outputs": [],
   "source": [
    "images = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "output_embedded_package_id": "1op2YSiQ_T2vTpjNfSZFKXAdbgIcFYYhA"
    },
    "id": "SyOJTakozHwn",
    "outputId": "159e5bf7-1f85-46e1-9039-acc56a6177bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_names = ['/content/DSC04974.JPG', '/content/IMG_20200513_195851.jpg']\n",
    "for img in img_names: display(Image.open(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX78ZcKoKsnJ"
   },
   "source": [
    "## <span style=\"color:purple\">Detecciones</span>\n",
    "#### <span style=\"color:black\">Probar el modelo con el umbral de IoU (índice de interceptación sobre unión utilizado en supresión no máxima) y el umbral de confianza establecidos en 0,5.</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "output_embedded_package_id": "1XOVeXzh4rr-MP3ISF7QDPJgTsvgm3ddd"
    },
    "id": "GSZRNSLI0p6U",
    "outputId": "431d1877-9aa2-42e3-b80b-4b6e1edb46c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = len(img_names)\n",
    "batch = load_images(img_names, model_size=_MODEL_SIZE)\n",
    "class_names = load_class_names(ruta + 'coco.names')\n",
    "n_classes = len(class_names)\n",
    "max_output_size = 10\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE,\n",
    "                max_output_size=max_output_size,\n",
    "                iou_threshold=iou_threshold,\n",
    "                confidence_threshold=confidence_threshold,\n",
    "                data_format = 'channels_last')\n",
    "\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
    "\n",
    "detections = model(inputs, training=False)\n",
    "\n",
    "with tf.variable_scope(\"other_charge\", reuse=True) as scope:\n",
    "    model_vars = tf.global_variables(scope='yolo_v3_model')\n",
    "    assign_ops = load_weights(model_vars, ruta + 'yolov3.weights')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(assign_ops)\n",
    "    detection_result = sess.run(detections, feed_dict={inputs: batch})\n",
    "    \n",
    "draw_boxes(img_names, detection_result, class_names, _MODEL_SIZE)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMNdp2NRnUixgawPUX179RF",
   "collapsed_sections": [],
   "name": "DetecciónObjetos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
